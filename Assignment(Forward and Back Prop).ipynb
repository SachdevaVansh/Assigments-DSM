{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5359e6-7bb8-4e58-b4a1-783f6f966d0d",
   "metadata": {},
   "source": [
    "#### Question 1-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c92a15-cbef-4c9b-b5d4-c6ce21ff0288",
   "metadata": {},
   "source": [
    "Forward propagation refers to storage and calculation of input data which is fed in forward direction through the network to generate an output. Hidden layers in neural network accepts the data from the input layer, process it on the basis of activation function and pass it to the output layer or the successive layers. Data flows in forward direction so as to avoid circular shape flow of data which will not generate an output. The network configuration that helps in forward propagation is known as feed-forward network.\n",
    "- During forward propagation, preactivation and activation takes place at each hidden layer and output layer node of neural network.\n",
    "- Preactivation is weighted sum of the inputs that is the linear transformation of the weights with respect to the available inputs. A neuron makes decision whether to pass the information further or not based on the sum and the activation function during forward propagation.\n",
    "- Activation is calculated weighted sum of the inputs passed to activation function. An activation function is the mathematical function that adds non-linearity to network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44fbb6-b7af-4938-a453-de31d2d85a6e",
   "metadata": {},
   "source": [
    "#### Question 2-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007eb5b9-5039-4a38-a1fb-187264f74a5e",
   "metadata": {},
   "source": [
    "If we are given the Weights W1 and the input X with the bias b is given , then we can perform the forward propagation simply by using:\n",
    "\n",
    "Z1=W1X + b\n",
    "\n",
    "Z1=np.dot(W1,X)+ b1\n",
    "\n",
    "Activation function=LTU/Sigmoid(Z1)\n",
    "A=sigmoid(Z1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cb83b-6d8e-4f71-98fa-08eca70ad2a2",
   "metadata": {},
   "source": [
    "#### Question 3-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0cd17-8c8e-4618-b24c-5dd7aff25eb0",
   "metadata": {},
   "source": [
    "1. Initialize weights randomly.\n",
    "2. Calculate the hidden layer unit values by multiplying input values with weights.\n",
    "3. Perform activation on the hidden layer values.\n",
    "4. Connect the hidden layer values to the output layer.\n",
    "5. Calculate the squared error loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85bb08-66f8-40dc-a0b8-dc0e11c72d65",
   "metadata": {},
   "source": [
    "#### Question 4-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211d4cb-d7c6-4a2d-9f57-e2f1639a304c",
   "metadata": {},
   "source": [
    "Weights set the standards for the neuron's signal strength. This value will determine the influence input data has on the output product. \n",
    "\n",
    "Biases give extra characteristics with a value of 1 that the neural network did not previously have. The neural network needs that extra information to efficiently propagate forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df36d2e-ea4c-4427-a38a-8fa89f8ceacd",
   "metadata": {},
   "source": [
    "#### Question 5-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ffdb4e-ddba-4584-baeb-c29f1a3a9e31",
   "metadata": {},
   "source": [
    "The softmax function is used as the activation function in the output layer of neural network models that predict a multinomial probability distribution. That is, softmax is used as the activation function for multi-class classification problems where class membership is required on more than two class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfbba5-46fe-4d2b-9d7c-b3268e7c8b24",
   "metadata": {},
   "source": [
    "#### Question 6-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb2855-d962-48cc-95fe-6f99f5e63f0d",
   "metadata": {},
   "source": [
    "Backpropagation is just a way of propagating the total loss back into the neural network to know how much of the loss every node is responsible for, and subsequently updating the weights in a way that minimizes the loss by giving the nodes with higher error rates lower weights, and vice versa.\n",
    "- Backpropagation is the essence of neural network training. It is the method of fine-tuning the weights of a neural network based on the error rate obtained in the previous epoch (i.e., iteration). Proper tuning of the weights allows you to reduce error rates and make the model reliable by increasing its generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5516c-d898-4654-88e6-19e09e89931c",
   "metadata": {},
   "source": [
    "#### Question 7-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b7f24-9af4-495b-a3dd-d3355d014edb",
   "metadata": {},
   "source": [
    "The following steps needs to be followed for doing the Backward Propagation in Neaural Networking:\n",
    "1. Calculate the cost function, C(w)\n",
    "2. Calculate the gradient of C(w) with respect to (w.r.t) all the weights, w, and biases, b, in your neural network (NN)\n",
    "3. Adjust the w and b proportional to the size of their gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4624531-a4d9-4984-ac7b-02ca5151d900",
   "metadata": {},
   "source": [
    "#### Question 8-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1ce6a-523d-4730-a4a5-da9bd58d9329",
   "metadata": {},
   "source": [
    "The chain rule allows us to find the derivative of a composite function. \n",
    "\n",
    "Letâ€™s first define how the chain rule differentiates a composite function, and then break it into its separate components to understand it better. If we had to consider again the composite function, h = g(f(x)), then its derivative as given by the chain rule is:\n",
    "\n",
    "dh/dx=dh/du.(du/dx)\n",
    "\n",
    "Here, u is the output of the inner function f (hence, u = f(x)), which is then fed as input to the next function g to produce h (hence, h = g(u)). Notice, therefore, how the chain rule relates the net output, h, to the input, x, through an intermediate variable, u."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fdd6d-2ad3-499b-8d9f-0779d2c30e00",
   "metadata": {},
   "source": [
    "#### Question 9-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a45ab-0875-4d98-8017-69875b176a85",
   "metadata": {},
   "source": [
    "The following are the issues/challeneges with Back Propagation in Neaural Networks:\n",
    "- It is sensitive to noisy data and irregularities. Noisy data can lead to inaccurate results.\n",
    "- Performance is highly dependent on input data.\n",
    "- Spending too much time training.\n",
    "- The matrix-based approach is preferred over a mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829db871-5ff9-4b98-9bb4-376fabd4ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
