{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4215e7f-50e3-4412-956f-9caa6672fd31",
   "metadata": {},
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance metric in KNN? How might this difference affect the performance of a \n",
    "        KNN classifier or regressor?\n",
    "\n",
    "Ans: The main difference between Euclidean distance and Manhattan distance is how they measure the distance between two points. Euclidean distance calculates the \n",
    "         straight-line distance, while Manhattan distance calculates the sum of absolute differences along each dimension. This difference can affect the performance of a \n",
    "         KNN classifier or regressor by altering the influence of each feature on the distance calculation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49518fe-4946-42f0-9714-f2a165487e64",
   "metadata": {},
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be used to determine the optimal k value?\n",
    "\n",
    "Ans: To choose the optimal value of k for a KNN classifier or regressor, techniques like cross-validation, grid search, or elbow method can be used. Cross-validation helps \n",
    "         evaluate k's performance on different data subsets. Grid search systematically explores a range of k values. The elbow method looks for the point of diminishing returns \n",
    "         in accuracy or error with increasing k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7ed49-a8c3-4d32-b067-3e08cc79d2fd",
   "metadata": {},
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In what situations might you choose one distance metric over the other?\n",
    "\n",
    "Ans: The choice of distance metric in KNN affects the performance by determining how distances between points are measured. Euclidean distance works well with continuous, \n",
    "         numeric features, while Manhattan distance is suitable for high-dimensional data or when features have different scales. The choice depends on the data characteristics \n",
    "         and problem requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465aa6b-ae1a-4555-9609-db48c531e5b1",
   "metadata": {},
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect the performance of the model? How might you go about tuning these \n",
    "        hyperparameters to improve model performance?\n",
    "\n",
    "Ans: n_neighbors: Determines the number of neighbors to consider. Higher values increase model complexity but may lead to overfitting.\n",
    "         weights: Determines the weight assigned to each neighbor during prediction. Options include 'uniform' (equal weight) and 'distance' (weight by inverse of distance).\n",
    "         p: Determines the power parameter for Minkowski distance metric. Default is 2 for Euclidean distance and 1 for Manhattan distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe72aa4-2051-494a-947b-d1db8e70bc27",
   "metadata": {},
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What techniques can be used to optimize the size of the training set?\n",
    "\n",
    "Ans: The size of the training set in KNN affects performance. Too small may result in high variance and overfitting, while too large can increase computation time. \n",
    "         Techniques like learning curves can help analyze the impact of different training set sizes, while techniques like resampling or data augmentation can optimize \n",
    "         training set size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652fb73e-9785-4fba-9480-576d30d5e44c",
   "metadata": {},
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you overcome these drawbacks to improve the performance of the model?\n",
    "\n",
    "Ans: Some potential drawbacks of KNN include: sensitivity to feature scaling, computationally expensive for large datasets, and the need for optimal choice of hyperparameters.\n",
    "         To overcome these drawbacks, feature scaling techniques can be applied, dimensionality reduction methods can be used, and hyperparameters can be tuned using techniques \n",
    "         like cross-validation or grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabde14-9b5a-40b0-8289-bb614cafd697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
