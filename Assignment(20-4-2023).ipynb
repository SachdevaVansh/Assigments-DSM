{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e36277-87f5-45a9-8eca-1b55457458ae",
   "metadata": {},
   "source": [
    "#### Question 1-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd15615-e5ba-4c47-a6ee-ee22be5a9bf3",
   "metadata": {},
   "source": [
    "Suppose there are two categories, i.e., Category A and Category B, and we have a new data point x1, so this data point will lie in which of these categories. To solve this type of problem, we need a K-NN algorithm. With the help of K-NN, we can easily identify the category or class of a particular dataset.\n",
    "\n",
    "K-NN algorithm can be used for Regression as well as for Classification but mostly it is used for the Classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73cfb6d-afaf-43b7-a52a-3f8be27ab6c4",
   "metadata": {},
   "source": [
    "#### Question 2-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b693d-5b1f-427b-97fe-ce6098dc69cc",
   "metadata": {},
   "source": [
    "- There is no particular way to determine the best value for \"K\", so we need to try some values to find the best out of them. The most preferred value for K is 5.\n",
    "- A very low value for K such as K=1 or K=2, can be noisy and lead to the effects of outliers in the model.\n",
    "- Large values for K are good, but it may find some difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29704e27-9c54-4883-b5a0-4c78c657045e",
   "metadata": {},
   "source": [
    "#### Question 3-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45157b-552f-4e92-9b30-b1f40f1eedae",
   "metadata": {},
   "source": [
    "In classification tasks, the user tries to predict a category, which is commonly represented as an integer label but actually represents a group of objects. For example, use label 0 for \"Rat\" and 1 for \"Cat\" to categorize photographs into \"Rat\" and \"Cat\" categories.\n",
    "\n",
    "The KNN classification algorithm will look at the k closest neighbors of the input you're trying to predict. The most common label among the k samples will then be output.\n",
    "\n",
    "If the user wishes to get a numerical value out of regression tasks (usually continuous). For example, it could be used to determine the value of a home or to rate the quality of a film.\n",
    "In this situation, the KNN method would combine the values associated with the k nearest examples from the one on which you wish to make a prediction to produce a single value. Normally, the average of the neighbors' k values would be used, however the median or a weighted average might also be used (or actually anything that makes sense to you for the task at hand)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce63a9b-bd60-4ffa-99e8-14496785f85e",
   "metadata": {},
   "source": [
    "#### Question 4-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f4b97-8eac-46d7-b47b-5c8613ba1208",
   "metadata": {},
   "source": [
    "The main concept for k-NN depends on calculating the distances between the tested, and the training data samples in order to identify its nearest neighbours. The tested sample is then simply assigned to the class of its nearest neighbour,\n",
    "\n",
    "In k-NN, the k value represents the number of nearest neighbours. This value is the core deciding factor for this classifier due to the k-value deciding how many neighbours influence the classification. When k=1, then the new data object is simply assigned to the class of its nearest neighbour. The neighbours are taken from a set of training data objects for where the correct classification is already known. k-NN works naturally with numerical data. Various numerical measures have been used such as Euclidean, Manhattan, Minkowsky distances. Amongst these, the Euclidean is the most widely used distance function with k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b861273-2ad4-4d8b-a137-aef7a470be28",
   "metadata": {},
   "source": [
    "#### Question 5-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4ed91-1bea-4690-8ba3-5a360dfffaf8",
   "metadata": {},
   "source": [
    "While applying k nearest neighbors approach in solving a problem, we can sometimes notice that there is a deterioration in the kNN performance when the number of predictors, p is large. The reason for this can be the high number of dimensions. This problem is known as the curse of dimensionality.\n",
    "\n",
    "It means that the test error tends to increase as the dimensionality of the problem (number of predictors) increases, unless the additional features are truly associated with the response. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c61e68-077f-4ee4-8fc4-80298616a09b",
   "metadata": {},
   "source": [
    "#### Question 6-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732060c9-d959-4d88-8e24-52f2e68466ef",
   "metadata": {},
   "source": [
    "The idea in kNN methods is to identify 'k' samples in the dataset that are similar or close in the space. Then we use these 'k' samples to estimate the value of the missing data points. Each sample's missing values are imputed using the mean value of the 'k'-neighbors found in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473fefe-0c59-4c59-ad65-b3462d64456f",
   "metadata": {},
   "source": [
    "#### Question 7-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91106f10-d70a-44ab-9dec-9ef462798dba",
   "metadata": {},
   "source": [
    "In classification tasks, the user seeks to predict a category, which is usually represented as an integer label, but represents a category of \"things\". For instance, you could try to classify pictures between \"cat\" and \"dog\" and use label 0 for \"cat\" and 1 for \"dog\".\n",
    "\n",
    "The KNN algorithm for classification will look at the k nearest neighbours of the input you are trying to make a prediction on. It will then output the most frequent label among those k examples.\n",
    "\n",
    "In regression tasks, the user wants to output a numerical value (usually continuous). It may be for instance estimate the price of a house, or give an evaluation of how good a movie is.\n",
    "\n",
    "In this case, the KNN algorithm would collect the values associated with the k closest examples from the one you want to make a prediction on and aggregate them to output a single value. usually, you would choose the average of the k values of the neighbours, but you could choose the median or a weighted average.\n",
    "\n",
    "For different specific problem, we could use both but regression makes more sense to me in order to predict some kind of a \"matching percentage \" between the user and the thing we want to recommand to him."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc150891-7328-43ef-94b1-7cabc556f1a1",
   "metadata": {},
   "source": [
    "#### Question 8-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effbb92-f797-4436-ae91-5cc853bc53be",
   "metadata": {},
   "source": [
    "Strengths of KNN Algorithm:\n",
    "1. KNN is pretty intuitive ans simple\n",
    "2. KNN has no assumptions\n",
    "3. No training Step required\n",
    "4. It constantly evolves\n",
    "5. Very easy to implement for multi-class problem\n",
    "6. Only one hyper-parameter \n",
    "\n",
    "Weakness of KNN Algorithm:\n",
    "1. KNN is slow algorithm\n",
    "2. Curse of Dimensionality\n",
    "3. KNN needs homogeneous features\n",
    "4. Chooisng the optimal number of neighbours\n",
    "5. Imbalanced data causes problems\n",
    "6. Outlier sensitive\n",
    "7. No capability to deal with missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a227243-01aa-4a07-985c-5ab0b92adf96",
   "metadata": {},
   "source": [
    "#### Question 9-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b3bd8-2565-4ced-9240-2e933edf0312",
   "metadata": {},
   "source": [
    "Euclidean Distance- Euclidean distance is the length of the line segment joining a given pair of points in a grid/graph. This is unique & is the shortest path between the given pair of points.\n",
    "\n",
    "Manhattan distance- Manhattan distance is the sum of all horizontal and vertical segments joining a given pair points in a grid/graph. There may be many Manhattan paths between the given pair of points, depending on the resolution of the grid/graph.\n",
    "\n",
    "If there are two points, point A(p1,q1) and point B(p2,q2) :\n",
    "\n",
    "- Euclidean distance=((p1-q1)^2+(p2-q2)^2)^1/2\n",
    "- Manhattan distance=|p1-q1|+|p2-q2|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596db9e-36b3-46ab-9850-37bcb8489346",
   "metadata": {},
   "source": [
    "#### Question 10-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edca380-4860-4f5e-8798-7e08d17fc307",
   "metadata": {},
   "source": [
    "Distance-based algorithms, such as the KNN, calculate the distance between data points to determine their similarity.\n",
    "\n",
    "Features with larger magnitudes can disproportionately influence the distance calculation, leading to biased results.\n",
    "\n",
    "Feature scaling addresses this issue by transforming the features to a comparable range or scale, ensuring that each feature contributes fairly to the final result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
