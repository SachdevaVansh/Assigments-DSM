{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e12e11-1eaf-4a27-a8e8-370258346107",
   "metadata": {},
   "source": [
    "#### Question 1-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7d7e4-f7a6-4afc-9604-f2998e020055",
   "metadata": {},
   "source": [
    "MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution.\n",
    "\n",
    "Example-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370f842f-5b22-4d97-9f60-3e4d1ea44d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[11, 2], [3, 7], [0, 10], [11, 8]]\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "model=scaler.fit(data)\n",
    "scaled_Data=model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc581277-cb81-4236-83f9-add66468059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.        ]\n",
      " [0.27272727 0.625     ]\n",
      " [0.         1.        ]\n",
      " [1.         0.75      ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1505d1-abd3-4515-a084-5b9456b0272d",
   "metadata": {},
   "source": [
    "#### Question 2-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd377cd7-143f-4fd9-aea4-338d9c5db8b8",
   "metadata": {},
   "source": [
    "Unit Vector Scaling-\n",
    "Scaling is done considering the whole feature vector to be of unit length. This usually means dividing each component by the Euclidean length of the vector (L2 Norm). In some applications (e.g., histogram features), it can be more practical to use the L1 norm of the feature vector.\n",
    "\n",
    "Like Min-Max Scaling, the Unit Vector technique produces values of range [0,1]. When dealing with features with hard boundaries, this is quite useful. For example, when dealing with image data, the colors can range from only 0 to 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd641cf5-9b27-4e49-947b-6e80bca41703",
   "metadata": {},
   "source": [
    "Example-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0271ffe6-0520-4d8c-a5b8-d026d4026c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4118d814-943e-4e28-9bd0-4a78581963a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af428806-0074-441b-b479-0824a578f8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659213e3-fccd-4dbb-8860-a1849e13fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72f8cb6d-4542-4ea5-80d1-62ecb27359f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8e4596c-d12c-4dd8-8bb4-81d5bc764b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(normalize(df[['fare']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c6ff0e4-171e-4b21-9114-99e9b153782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb69d14-4fb1-49c4-9c54-124204a140d8",
   "metadata": {},
   "source": [
    "#### Question 3-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62412fe-331b-4661-9757-d231f55ce10e",
   "metadata": {},
   "source": [
    "Principal component analysis, or PCA, is a dimensionality reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "\n",
    "The idea of PCA is to reduce the number of variables of a data set, while preserving as much information as possible.\n",
    "\n",
    "Example of it's applications-\n",
    "- PCA is used to visualize multidimensional data.\n",
    "- It is used to reduce the number of dimensions in healthcare data.\n",
    "- PCA can help resize an image.\n",
    "- It can be used in finance to analyze stock data and forecast returns.\n",
    "- PCA helps to find patterns in the high-dimensional datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc769a9-955a-4458-8f62-cca764d16976",
   "metadata": {},
   "source": [
    "#### Question 4-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753a90b-5676-479a-b411-90ac54022730",
   "metadata": {},
   "source": [
    "We can apply principal component analysis (PCA) for feature extraction in the following ways:\n",
    "\n",
    "1. Feature extraction is about transforming features into new feature subspace while retaining information in original features.\n",
    "2. New features subspace is created by transforming d-dimensional data set into k-dimensional data set by using projection matrix. Projection matrix is constructed by selecting K most important eigenvectors.\n",
    "3. Most important eigenvectors are selected by sorting eigenvalues and finding their explained variance ratio.\n",
    "4. Eigenvectors & eigenvalues are created by doing eigendecomposition of covariance matrix of original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7e551-8c53-4d52-b535-1de9abf6032c",
   "metadata": {},
   "source": [
    "#### Question 5-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f024384-4f6c-499b-858a-fa194dc3b5cf",
   "metadata": {},
   "source": [
    "As the dataset conatins fetaures like price,rating these features can be normalized using the MinMaxScaler function of the sklearn library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa282b5-9b1b-4de7-848d-822cffbef7f2",
   "metadata": {},
   "source": [
    "Suppose the Price and Rating are in the form a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "424a8c3f-1d7e-4198-93d5-8311cb5f930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=[200,145,36,1000,12,236,98,698,475,700]\n",
    "Rating=[1,2,4,2,5,7,8,9,10,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51c9992e-9124-4fb1-ac84-83aa126d0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daacc0d6-2e12-482d-acf1-b68e33f930e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "118bc483-766e-45e4-af38-14b536ade866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform([Price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dad47928-9de8-4861-a98f-d06ce8f58bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform([Rating])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c32c51-b574-411f-9b64-1684056d94a8",
   "metadata": {},
   "source": [
    "#### Question 6-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84227d-e848-40ac-be74-735d053250d5",
   "metadata": {},
   "source": [
    "We can use the following steps of PCA Algoritm in order to reduce the dimensionality of the dataset:\n",
    "\n",
    "1. Standardize the dataset:Standardizing / normalizing the dataset is the first step one would need to take before performing PCA. The PCA calculates a new projection of the given data set representing one or more features.\n",
    "2. Construct the covariance matrix: Once the data is standardized, the next step is to create n X n-dimensional covariance matrix, where n is the number of dimensions in the dataset.\n",
    "3. Perform Eigendecomposition of covariance matrix: The next step is to decompose the covariance matrix into its eigenvectors and eigenvalues. The eigenvectors of the covariance matrix represent the principal components (the directions of maximum variance), whereas the corresponding eigenvalues will define their magnitude.\n",
    "4. Selection of most important Eigenvectors / Eigenvalues: Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors. Select k eigenvectors, which correspond to the k largest eigenvalues, where k is the dimensionality of the new feature subspace ().\n",
    "5. Projection matrix creation of important eigenvectors: Construct a projection matrix, W, from the top k eigenvectors.\n",
    "6. Training / test dataset transformation: Finally, transform the d-dimensional input training and test dataset using the projection matrix to obtain the new k-dimensional feature subspace.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d439be-f0a3-4ff4-aafd-7f31233369c2",
   "metadata": {},
   "source": [
    "#### Question 7-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6549fb1a-96a1-4c8f-b9a5-918b4d9c5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[1,5,10,1,5,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "500c7cc4-79fd-4d3f-b576-502a10053904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "896959ee-09db-495f-be89-83acf94cd912",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80e6d961-fd48-4d42-a50b-fcfb97ea32bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b36e672c-65b7-41e6-a9fc-d16392d1e5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform([data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e250115d-5b20-4243-9f7e-d95baa14c6cd",
   "metadata": {},
   "source": [
    "#### Question 8-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8208bc3-b435-47bc-8dad-72e839cb3f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
